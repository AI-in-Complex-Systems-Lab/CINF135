{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab #3\n",
    "\n",
    "Data exploration is a crucial step in the AI/ML pipeline. Before we dive into complex algorithms, we need to understand the basics of our dataset. This process involves:\n",
    "\n",
    "- Summarizing the main characteristics of the dataset\n",
    "- Detecting any anomalies or outliers that may affect model performance\n",
    "- Unveiling the structure and patterns in the data by visualizing \n",
    "\n",
    "We will use these Python librares: pandas for data exploration, matplotlib and seaborn for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "- Here, we load the Iris dataset using Pandas. We use the 'head', 'info', and 'describe' methods to get an initial understanding of the dataset's structure, data types, and some basic statistical details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/iris_dataset.csv')\n",
    "\n",
    "# Initial exploration\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "- Missing values can significantly affect the performance of ML models. We handle them by imputing using the mean of each column. This is a simple strategy, but there are more sophisticated methods available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values - Simple Imputation\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Check if there are any missing values left\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalization is crucial when features have different scales, as it standardizes the range of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization (if necessary)\n",
    "scaler = StandardScaler()\n",
    "df['target'] = np.ceil(df['target']).astype(int)\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df.drop('target', axis=1)), columns=df.columns[:-1])\n",
    "df_scaled['target'] = df['target']\n",
    "\n",
    "# df = df_scaled # uncomment if you want to use the scaled values\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistical Analysis\n",
    "\n",
    "- Descriptive statistics provide important insights into the data. Mean and median offer information about the central tendency, while standard deviation tells us about the spread of the data. These metrics are foundational for understanding any dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Mean:\\n\", df.mean())\n",
    "print(\"Median:\\n\", df.median())\n",
    "print(\"Standard Deviation:\\n\", df.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "- Visualization is key to understanding the distribution and relationship between variables. Histograms show the distribution of each feature, box plots highlight outliers, and scatter plots (using pairplot) reveal the relationships between pairs of features, colored by the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for feature distributions\n",
    "df.hist(figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots to identify outliers\n",
    "df.boxplot(figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot (advanced)\n",
    "sns.pairplot(df, hue='target', corner=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example SVC (Support Vector Classifier)\n",
    "\n",
    "- Let's create a classifier that can predict the target class using only two attributes.\n",
    "- We should choose two attributes that can be easily separated based on their class. (Check out the pairplot we made in the last step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are various types of [SVC](https://scikit-learn.org/stable/modules/svm.html) and different parameters that you can use according to your needs.\n",
    "- Let's see an example with four different models that use 'petal width (cm)' and 'petal length (cm)' as attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification using Support Vector Classifier (SVC)\n",
    "X = df[['petal width (cm)', 'petal length (cm)']].values\n",
    "y = df['target'].values\n",
    "\n",
    "# Create a meshgrid to plot decision boundary\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "\n",
    "C = 1.0  # SVM regularization parameter\n",
    "models = (\n",
    "    SVC(kernel=\"linear\", C=C),\n",
    "    SVC(kernel=\"rbf\", gamma=0.7, C=C),\n",
    "    SVC(kernel=\"poly\", degree=3, gamma=\"auto\", C=C),\n",
    "    LinearSVC(C=C, max_iter=10000, dual=True),\n",
    ")\n",
    "models = (clf.fit(X, y) for clf in models)\n",
    "\n",
    "# title for the plots\n",
    "titles = (\n",
    "    \"SVC with linear kernel\",\n",
    "    \"SVC with RBF kernel\",\n",
    "    \"SVC with polynomial (degree 3) kernel\",\n",
    "    \"LinearSVC (linear kernel)\",\n",
    ")\n",
    "\n",
    "fig, sub = plt.subplots(2, 2, figsize=(12,10))\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "    # Plot decision boundary\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    ax.contourf(xx, yy, Z, alpha=0.2, cmap='coolwarm')\n",
    "\n",
    "    # Scatter plot with color-coded target variable\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Petal Width (cm)')\n",
    "    ax.set_ylabel('Petal Length (cm)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
